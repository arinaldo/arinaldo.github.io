<h2>References</h2>


<b>Textbooks and expository articles on minimax theory</b>
<tr>
<td colspan="2" align="center" valign="top"> <br>
<table width="80%">
<tr><td colspan="2" bgcolor="#0000FF"> <!--<img src="transparent.gif" height="1" border="0"></td></tr>-->
</tr></td><tr>
	</table>
   <ul>
       <li> Tsybakov, A. (2008). Introduction to Nonparametric Estimation,
    	Springer.
	<li> Yu. B. (1997) Assuad, Fano, and Le Cam, Festschrift for Lucien Le
	Cam,
	<a href="https://www.stat.berkeley.edu/~binyu/ps/LeCam.pdf">pdf</a>.	
	<li> John Duchi's notes on minimax theory from his class <a
	    href="http://stanford.edu/class/stats311/">Statistics
	    311/Electrical Engineering 377.</a>
	<li> Philippe's Rgiollet noes on minimax theory from his <a
	    href="http://www-math.mit.edu/~rigollet/PDFs/RigNotes15.pdf">class on high
	    dimensional statistics.</a>
	</ul>

	<br><br>
<b>Lecture 3, Wed Jan 25</b>
<tr>
<td colspan="2" align="center" valign="top"> <br>
<table width="80%">
<tr><td colspan="2" bgcolor="#0000FF"> <!--<img src="transparent.gif" height="1" border="0"></td></tr>-->
</tr></td><tr>
    </table>
    In the 90's Donoho and Johnstone made remarkable contributions to non-parametric functional estimation under Gaussian noise. Their techniques
    for deriving minimax lower bounds are different than the one covered in
    class and are more classical, but certainly important. For a comprehensive
    treatment, see the draft of the book
    <ul> "Gaussian estimation: Sequence and wavelet models" by I. Johnstone,
	available <a href="
	    http://statweb.stanford.edu/~imj/GE09-08-15.pdf">here</a>.
	    </ul>

	    For a textbook treatment of the classic minimax theory, see
	    <ul>
		<li> Chapter 5 of Theory of Point Estimation (1998), by
		E.L.Lehman and G. Casella, Springer, second edition.
	    </ul>


	<br><br>

<b>Lecture 4, Mon Jan 30</b>
<tr>
<td colspan="2" align="center" valign="top"> <br>
<table width="80%">
<tr><td colspan="2" bgcolor="#0000FF"> <!--<img src="transparent.gif" height="1" border="0"></td></tr>-->
</tr></td><tr>
    </table>
    For a statement and proof of Fano's lemma, see page 39 of
	    </ul>
	    <li> Cover and Thomas, Elements of Information Theory, 1999.
	    </ul>

	<br><br>

<b>Lecture 6, Mon Feb 6</b>
<tr>
<td colspan="2" align="center" valign="top"> <br>
<table width="80%">
<tr><td colspan="2" bgcolor="#0000FF"> <!--<img src="transparent.gif" height="1" border="0"></td></tr>-->
</tr></td><tr>
    </table>
    For more on mutual information and differential entropy of Gaussian
    variates, see
	    </ul>
	    <li> Cover and Thomas, Elements of Information Theory, 1999.
	    </ul>

    
   For lower bounds on the model selection problem in sparse linear regression,
   see
	    </ul>
	    <li>  M. J. Wainwright. Information-theoretic bounds on sparsity
	    recovery in the high-dimensional and noisy setting. IEEE Trans.
	    Info. Theory, 55:5728– 5741, 2009. 
	</ul>


	<br><br>


<b>Lecture 9, Mon Feb 20</b>
<tr>
<td colspan="2" align="center" valign="top"> <br>
<table width="80%">
<tr><td colspan="2" bgcolor="#0000FF"> <!--<img src="transparent.gif" height="1" border="0"></td></tr>-->
</tr></td><tr>
    </table>
    The sparse Varshamov-Gilber Lemma and the examples covered in class were
    taken from the refeence
	    </ul>
	    <li>  Raskutti, G., Wainwright, M. and Yu. B. (2011). Minimax rates of estimation for high-dimensional linear
	    regression over lq-balls, IEEE TRANSACTIONS ON INFORMATION THEORY,
	    57(10), 6976-6994.
	    </ul>
Other relevant references for the problem of deriving minimax lower bound for
sparse high dimensional regression are
<ul>
    <li> P. Rigollet and A. B. Tsybakov (2011). Exponential screening and optimal
    rates of sparse estimation, Annals of Statistics, 39(2),  731-771.
    <li> E. J. Candès and M. A. Davenport. How well can we estimate a sparse
    vector? Applied and Computational Harmonic Analysis 34, 317--323.
</ul>
    
For other versions of the sparse Varshamov-Gilbert Lemma, see
<ul>
    <li> L. Birgé and P. Massart, “Gaussian model selection,” J. Eur. Math.
    Soc., vol. 3, pp. 203–-268, 2001.
    <li> Lemma 4.10 in Massart, P. (2007). Concentration Inequalities and Model
    Selection, Springer Lecture Notes in Mathematic, no 1896.
</ul>

	<br><br>


